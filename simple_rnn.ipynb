{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import re\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adagrad\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"/data\"):\n",
    "    data_path = \"/data\"\n",
    "else:\n",
    "    data_path = \"data\"\n",
    "    \n",
    "if os.path.exists(\"/output\"):\n",
    "    output_path = \"/output\"\n",
    "else:\n",
    "    output_path = \"output\"\n",
    "    \n",
    "if os.path.exists(\"/glove\"):\n",
    "    glove_path = \"/glove\"\n",
    "else:\n",
    "    glove_path = \"glove\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(data_path + '/train.csv')\n",
    "df_test = pd.read_csv(data_path + '/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs(glove_path + '/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = df_train['comment_text'].map(lambda text : len(text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    m = X.shape[0]\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    \n",
    "    for i in range(m): \n",
    "        sentence_words = X[i].lower().split()\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        for j in range(min(len(sentence_words), max_len)):\n",
    "            w = sentence_words[j]\n",
    "            if w in word_to_index:\n",
    "                X_indices[i, j] = word_to_index[w]\n",
    "            \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sentences_to_indices(df_train['comment_text'].values, words_to_index, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = df_train[['toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sentences_to_indices(df_test['comment_text'].values, words_to_index, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 50\n",
    "vocab_len = len(words_to_index) + 1\n",
    "emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "\n",
    "for word, index in words_to_index.items():\n",
    "    emb_matrix[index, :] = word_to_vec_map[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_33 (Embedding)     (None, 100, 50)           20000050  \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 100, 100)          40400     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 20,046,206\n",
      "Trainable params: 45,956\n",
      "Non-trainable params: 20,000,250\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding = Embedding(vocab_len, emb_dim, trainable = False, weights=[emb_matrix])\n",
    "\n",
    "def get_model(input_shape):\n",
    "    x_input = Input(shape=input_shape, dtype='int32')\n",
    "\n",
    "    x = embedding(x_input)\n",
    "    x = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=x_input, outputs=x)\n",
    "    return model\n",
    "    \n",
    "model = get_model(input_shape=(100,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred)\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "    return value\n",
    "model.compile(loss='binary_crossentropy', metrics=[auc, 'accuracy'], optimizer=Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "  3200/143613 [..............................] - ETA: 16:58 - loss: 0.1635 - auc: 0.6882 - acc: 0.9478"
     ]
    }
   ],
   "source": [
    "file_path = output_path + \"/weights_base.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [checkpoint]\n",
    "model.fit(X_train, Y_train, validation_split=0.1, epochs=2, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, validation_split=0.1, epochs=2, batch_size=128, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(file_path, custom_objects={'auc':auc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting.....\n",
      "153164/153164 [==============================] - 79s 517us/step\n"
     ]
    }
   ],
   "source": [
    "print(\"predicting.....\")\n",
    "Y_test = model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame()\n",
    "df_submission['id'] = df_test['id']\n",
    "for i, column in enumerate([\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]):\n",
    "    df_submission[column] = Y_test[:, i]\n",
    "df_submission.to_csv(output_path + '/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
